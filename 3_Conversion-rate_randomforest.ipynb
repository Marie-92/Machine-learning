{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eiKSLYG8XvO"
      },
      "source": [
        "# Challenge : predict conversions üèÜüèÜ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nsSGw4BpKCbC"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGhdl7Bt2xZd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHgro65rxKF7"
      },
      "source": [
        "# Read file with labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "W1AU8AH8u0qd",
        "outputId": "00698a97-027b-493b-a2e4-33fdcc295abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set with labels (our train+test) : (284580, 6)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('https://julie-2-next-resources.s3.eu-west-3.amazonaws.com/full-stack-full-time/projects-supervised-machine-learning-ft/walmart-sales-ft/conversion_data_train.csv')\n",
        "print('Set with labels (our train+test) :', df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeDR5O0PKCbg",
        "outputId": "0b79ebd5-652b-4fcc-fe8e-f4b593dff0ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>age</th>\n",
              "      <th>new_user</th>\n",
              "      <th>source</th>\n",
              "      <th>total_pages_visited</th>\n",
              "      <th>converted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>China</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>Direct</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UK</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>Ads</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Germany</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Seo</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>US</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>Seo</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>US</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>Direct</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   country  age  new_user  source  total_pages_visited  converted\n",
              "0    China   22         1  Direct                    2          0\n",
              "1       UK   21         1     Ads                    3          0\n",
              "2  Germany   20         0     Seo                   14          1\n",
              "3       US   23         1     Seo                    3          0\n",
              "4       US   28         1  Direct                    3          0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCcd0imbKCbm"
      },
      "outputs": [],
      "source": [
        "df = df.sample(50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNuhCFiKCbo"
      },
      "source": [
        "## Model using ALL features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgATckKOKCbq",
        "outputId": "cda391e5-8c3a-48c5-a132-d0210df87fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Separating labels from features...\n",
            "...Done.\n",
            "\n",
            "Y : \n",
            "158287    0\n",
            "242596    0\n",
            "219211    0\n",
            "197826    0\n",
            "238836    0\n",
            "Name: converted, dtype: int64\n",
            "\n",
            "X :\n",
            "       country  age  new_user  source  total_pages_visited\n",
            "158287   China   18         1     Ads                    2\n",
            "242596   China   35         0     Seo                    1\n",
            "219211      US   22         1  Direct                    7\n",
            "197826      US   38         1  Direct                    5\n",
            "238836   China   19         0     Seo                    2\n"
          ]
        }
      ],
      "source": [
        "print(\"Separating labels from features...\")\n",
        "features_list = df.columns[:-1]\n",
        "target_variable = \"converted\"\n",
        "\n",
        "X = df.loc[:,features_list]\n",
        "Y = df.loc[:,target_variable]\n",
        "\n",
        "print(\"...Done.\")\n",
        "print()\n",
        "\n",
        "print('Y : ')\n",
        "print(Y.head())\n",
        "print()\n",
        "print('X :')\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsN1ZPBdKCbu"
      },
      "outputs": [],
      "source": [
        "numeric_features = ['age', 'new_user', 'total_pages_visited']\n",
        "categorical_features = ['country', 'source']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jceKAOWKCbx",
        "outputId": "22e8c7ea-32fa-4cc1-d9c7-f876fd8b72bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dividing into train and test sets...\n",
            "...Done.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Dividing into train and test sets...\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
        "print(\"...Done.\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PocpSSS0KCbz"
      },
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')), \n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), \n",
        "    ('encoder', OneHotEncoder(drop='first')) \n",
        "    ])\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OV528seKCb1"
      },
      "outputs": [],
      "source": [
        "X_train = preprocessor.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIJt3TcPKCb4"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "Y_train = encoder.fit_transform(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F5EMTt-KCb5"
      },
      "outputs": [],
      "source": [
        "X_test = preprocessor.fit_transform(X_test)\n",
        "Y_test = encoder.fit_transform(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uGKtxPnKCb7",
        "outputId": "5aab45bc-7df5-4292-fad3-574da66f8ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid search...\n",
            "...Done.\n"
          ]
        }
      ],
      "source": [
        "print(\"Grid search...\")\n",
        "random_forest = RandomForestClassifier()\n",
        "\n",
        "# Grid of values to be tested\n",
        "params = {\n",
        "    'max_depth': [4, 6, 8, 10],\n",
        "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
        "    'min_samples_split': [1, 2, 4, 6, 8],\n",
        "    'n_estimators': [2, 4, 6, 8, 10, 12]\n",
        "}\n",
        "print(params)\n",
        "gridsearch = GridSearchCV(random_forest, param_grid = params, cv = 3, verbose = 1) # cv : the number of folds to be used for CV\n",
        "gridsearch.fit(X_train, y_train)\n",
        "print(\"...Done.\")\n",
        "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
        "print(\"Best validation accuracy : \", gridsearch.best_score_)\n",
        "\n",
        "random_forest.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zgXBeh7KCb9",
        "outputId": "fa3a27d2-85cc-4c80-a26e-a7114f4482dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1-score on training set :  0.777391304347826\n",
            "f1-score on test set :  0.7686832740213523\n"
          ]
        }
      ],
      "source": [
        "Y_train_pred = random_forest.predict(X_train)\n",
        "Y_test_pred = random_forest.predict(X_test)\n",
        "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))\n",
        "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRVoNsM1KCb_",
        "outputId": "1eb2fd51-f268-499e-f1e1-005e02292e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grid search...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=7,\n",
              "                                                         min_samples_split=3),\n",
              "                   n_estimators=60)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Grid of values to be tested\n",
        "params = {\n",
        "    'max_depth': [4, 6, 8, 10],\n",
        "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
        "    'min_samples_split': [1, 2, 4, 6, 8],\n",
        "    'n_estimators': [2, 4, 6, 8, 10, 12]\n",
        "}\n",
        "print(params)\n",
        "gridsearch = GridSearchCV(decision_tree, param_grid = params, cv = 3, verbose = 1) # cv : the number of folds to be used for CV\n",
        "gridsearch.fit(X_train, y_train)\n",
        "\n",
        "decision_tree.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT9-CN2lKCcD",
        "outputId": "53ac30d6-81c7-4245-d465-dd9e88147ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1-score on training set :  0.8760597496972143\n",
            "f1-score on test set :  0.7385103011093502\n"
          ]
        }
      ],
      "source": [
        "Y_train_pred = decision_tree.predict(X_train)\n",
        "Y_test_pred = decision_tree.predict(X_test)\n",
        "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))\n",
        "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59f1PfBSKCcG",
        "outputId": "1b8694c9-60bb-4d76-8d25-e43095445272"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=7, min_samples_split=3, n_estimators=60)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.append(X_train,X_test,axis=0)\n",
        "Y = np.append(Y_train,Y_test)\n",
        "\n",
        "random_forest.fit(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESScMoDWKCcL",
        "outputId": "9fe602e6-c7ef-480a-8517-c59dffb3f538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction set (without labels) : (31620, 5)\n"
          ]
        }
      ],
      "source": [
        "data_without_labels = pd.read_csv('conversion_data_test.csv')\n",
        "print('Prediction set (without labels) :', data_without_labels.shape)\n",
        "\n",
        "# Warning : check consistency of features_list (must be the same than the features \n",
        "# used by your best classifier)\n",
        "#features_list = ['total_pages_visited', 'age', 'new_user', 'country']\n",
        "X_without_labels = data_without_labels.iloc[:, [True, True, True, True, True]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c7obZHHKCcN"
      },
      "outputs": [],
      "source": [
        "X_without_labels = preprocessor.transform(X_without_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duVfqJfHKCcP"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    'converted': random_forest.predict(X_without_labels)\n",
        "}\n",
        "\n",
        "Y_predictions = pd.DataFrame(columns=['converted'],data=data)\n",
        "Y_predictions.to_csv('conversion_data_test_predictions_MarieP.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}